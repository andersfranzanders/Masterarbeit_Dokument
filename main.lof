\select@language {ngerman}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Statistische Werte eines Signals \IeC {\"u}ber das Intervall [50,200]\relax }}{8}{figure.caption.5}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Ein 1.8-Sekunden langes Signal. Oben: Der Zeitbereich mit drei klar erkennbaren Events. Unten: Das Frequenz-Spectrum des gesamten Signals mit logarithmisierten Achsen.\relax }}{10}{figure.caption.6}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Windowing: Die Zerlegung eines Signals in k\IeC {\"u}rzere Fenster.\relax }}{10}{figure.caption.7}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Das Hamming-Window\relax }}{11}{figure.caption.8}
\contentsline {figure}{\numberline {2.5}{\ignorespaces STFT des Beispiel-Signals aus Abbildung \ref {img:siganlWindows}\relax }}{11}{figure.caption.9}
\contentsline {figure}{\numberline {2.6}{\ignorespaces Schematische \IeC {\"U}bersicht \IeC {\"u}ber die Organe der Spracherzeugung. Lung = Lunge, Vocal Chords = Stimmb\IeC {\"a}nder, Pharynx = Rachen, Velum = Halsz\IeC {\"a}pfchen, Mouth Cavity = Mundraum, Nasal Cavity = Nasenraum \cite {speechProduction}\relax }}{12}{figure.caption.10}
\contentsline {figure}{\numberline {2.7}{\ignorespaces Schematische \IeC {\"u}ber das Source-Filter-Model \cite [nach Source estimation, S. 17]{ricardo_ceps}\relax }}{13}{figure.caption.11}
\contentsline {figure}{\numberline {2.8}{\ignorespaces Zeit-Bereiche der periodic und der turbulance Source \cite [Source]{speechAcoustics}\relax }}{13}{figure.caption.12}
\contentsline {figure}{\numberline {2.9}{\ignorespaces Betrachtung der Frequenz-Bereiche des Source-Filer-Modell (nach: \cite [Source Estimation, S. 3]{ricardo_ceps})\relax }}{14}{figure.caption.13}
\contentsline {figure}{\numberline {2.10}{\ignorespaces Grundfrequenz und harmonische Obert\IeC {\"o}ne eines Sprachsignals.\relax }}{15}{figure.caption.14}
\contentsline {figure}{\numberline {2.11}{\ignorespaces Formanten im Sprach-Signal (nach: \cite {benade})\relax }}{15}{figure.caption.15}
\contentsline {figure}{\numberline {2.12}{\ignorespaces Spectogram von Baby-Weinen. Rot = Hohe Amplituden, Blau = niedrige Amplituden. Oben: Zeit-Bereich. Mitte: Spectogram mit einer Fensterl\IeC {\"a}nge von $\SI {185}{\milli \second }$(8192-Sample DFT). Unten: Spectogram mit einer Fensterl\IeC {\"a}nge von $\SI {5}{\milli \second }$\relax }}{16}{figure.caption.16}
\contentsline {figure}{\numberline {2.13}{\ignorespaces Veranschaulichung des Grundvokabulars\relax }}{17}{figure.caption.17}
\contentsline {figure}{\numberline {2.14}{\ignorespaces (1) Pitch of Shift (2) Maximale Grundfrequenz (3) Minimum der Grundfrequenz (4) Biphonation (5) Double Harmonic Break (6) Vibrato (7) Glide (8) Furcation \cite [S. 142]{signal}\relax }}{19}{figure.caption.18}
\contentsline {figure}{\numberline {2.15}{\ignorespaces Entscheidungsbaum, der durch den ID3-Algorithmus f\IeC {\"u}r den Datensatz aus Beispiel \ref {tab:id3_example} erzeugt wurde.\relax }}{22}{figure.caption.20}
\contentsline {figure}{\numberline {2.16}{\ignorespaces Confusion-Matrix (nach: \cite [S. 214]{machine_kubat})\relax }}{25}{figure.caption.21}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces \IeC {\"U}berblick \IeC {\"u}ber die Verarbeitungs-Pipeline dieser Arbeit\relax }}{30}{figure.caption.22}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Markierung stimmhafter Bereiche in einem Audiosignal. Oben Schwarz: Das Eingangssignal $x[\tmspace +\thickmuskip {.2777em}]$. Oben Rot: Klassifizierung in stimmhaft/Stille. Unten Rot: Die f\IeC {\"u}nf erkannten Cry-Units.\relax }}{31}{figure.caption.23}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Aufbau eines VAD-Algorithmus\relax }}{32}{figure.caption.24}
\contentsline {figure}{\numberline {4.3}{\ignorespaces \IeC {\"U}bersicht \IeC {\"u}ber alle Features, die f\IeC {\"u}r die Voice Activity Detection erprobt wurden.\relax }}{38}{figure.caption.37}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Das RMS-Feature bei verschiedenen Signal/Rausch-Abst\IeC {\"a}nden. Schwarz: Eingangs-Signal $x[\tmspace +\thickmuskip {.2777em}]$. Gr\IeC {\"u}n: Klassifizierung in Stimmhaft/Stille. Rot: Feature-Wert.\relax }}{39}{figure.caption.39}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Thresholding eines Features. Schwarz: Das Eingangssignal $x[\tmspace +\thickmuskip {.2777em}]$. Gr\IeC {\"u}n: Klassifizierung in Stimmhaft/Stille. Rot: RMS-Feature. Orange: Grenzwert\relax }}{40}{figure.caption.41}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Zusammenfassung klassifizierter Signalfenster zu Cry-Units\relax }}{43}{figure.caption.45}
\contentsline {figure}{\numberline {4.7}{\ignorespaces Beziehung zwischen agrenzenden Cry-Units, nach \cite [S. 2]{vad_entropy}\relax }}{44}{figure.caption.46}
\contentsline {figure}{\numberline {4.8}{\ignorespaces Klassifizierung vor dem Decision Smoothing\relax }}{46}{figure.caption.47}
\contentsline {figure}{\numberline {4.9}{\ignorespaces Klassifikation vor und nach dem Decision Smoothing\relax }}{48}{figure.caption.48}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {.1}{\ignorespaces Boxplot-Auswertung \IeC {\"u}ber Sensitivity, Specificity und Accuracy der beiden VAD-Modelle\relax }}{56}{figure.caption.52}
